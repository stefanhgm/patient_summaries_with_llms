{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Labelings\n",
    "\n",
    "This notebooks is used to analyse the labeling of the dataset done by two annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bioc import biocxml\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General defintions\n",
    "red_flagged_ids = [10, 18, 20, 43, 44, 48, 50, 53, 62, 66, 67, 69, 72, 75, 86, 95, 98, 100, 110, 111, 113, 115, 123, 125, 134, 137]\n",
    "exluded_ids = red_flagged_ids\n",
    "included_ids = list(range(0, 13))\n",
    "included_ids = [x for x in included_ids if x not in exluded_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label defintions\n",
    "labels = {\n",
    "    'c': 'condition_unsupported',\n",
    "    'p': 'procedure_unsupported',\n",
    "    'm': 'medication_unsupported',\n",
    "    't': 'time_unsupported',\n",
    "    'l': 'location_unsupported',\n",
    "    'n': 'number_unsupported',\n",
    "    'na': 'name_unsupported',\n",
    "    'w': 'word_unsupported',\n",
    "    'o': 'other_unsupported',\n",
    "    'co': 'contradicted_fact',\n",
    "    'i': 'incorrect_fact'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read labelings in BioC format\n",
    "data_path = '/home/s/s_hegs02/scratch/MedTator'\n",
    "data_path = Path(data_path)\n",
    "labeling_1_path = data_path / '10_label_silver_examples_annotator_1' / 'labelled-dataset-BioC.xml'\n",
    "labeling_2_path = data_path / '11_label_silver_examples_annotator_2' / 'labelled-dataset-BioC.xml'\n",
    "with open(labeling_1_path, 'rb') as fp:\n",
    "    labeling_1 = biocxml.load(fp)\n",
    "with open(labeling_2_path, 'rb') as fp:\n",
    "    labeling_2 = biocxml.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict of document ids and their annotations\n",
    "def extract_id(document_name):\n",
    "    return document_name.split('.')[0].split('_')[-1]\n",
    "\n",
    "def parse_label(annotation):\n",
    "    # Create a dict of start index, end index, length, label, text\n",
    "    start = annotation.locations[0].offset\n",
    "    end = start + annotation.locations[0].length\n",
    "    length = annotation.locations[0].length\n",
    "    # Get all character before digit of annotation id\n",
    "    label_prefix = str(re.findall(r'[^\\d]+', annotation.id)[0])\n",
    "    label = labels[label_prefix.lower()]\n",
    "    text = annotation.text\n",
    "    return {'start': start, 'end': end, 'length': length, 'label': label, 'text': text}\n",
    "\n",
    "# Sort lists of dict by dict key start\n",
    "def sort_by_start(l):\n",
    "    return sorted(l, key=lambda k: k['start'])\n",
    "\n",
    "labeling_1_dict = {}\n",
    "for document in labeling_1.documents:\n",
    "    labeling_1_dict[extract_id(document.id)] = sort_by_start([parse_label(a) for a in document.passages[0].annotations])\n",
    "labeling_2_dict = {}\n",
    "for document in labeling_2.documents:\n",
    "    labeling_2_dict[extract_id(document.id)] = sort_by_start([parse_label(a) for a in document.passages[0].annotations])\n",
    "    \n",
    "# Only keep documents with ids in included_ids\n",
    "labeling_1_dict = {k: v for k, v in labeling_1_dict.items() if int(k) in included_ids}\n",
    "labeling_2_dict = {k: v for k, v in labeling_2_dict.items() if int(k) in included_ids}\n",
    "assert labeling_1_dict.keys() == labeling_2_dict.keys()\n",
    "\n",
    "# Create dataframe of document ids and their annotations\n",
    "data_list = []\n",
    "for id in labeling_1_dict.keys():\n",
    "    data_list.append({'id': id, 'labels_1': labeling_1_dict[id], 'labels_2': labeling_2_dict[id]})\n",
    "data = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which annotations are in agreement with an overlap\n",
    "overlap_ratio = 0.8\n",
    "\n",
    "def get_overlap(a, b):\n",
    "    # Get the overlap of two annotations\n",
    "    return max(0, min(a['end'], b['end']) - max(a['start'], b['start'])) / min(a['length'], b['length'])\n",
    "    \n",
    "def get_agreement_list(a_list, b_list, same_label=False):\n",
    "    # Get the agreement of two lists of annotations\n",
    "    agreement_list = []\n",
    "    for a in a_list:\n",
    "        for b in b_list:\n",
    "            # labels a and b contain start, end, length, label, text as dict\n",
    "            overlap = get_overlap(a, b)\n",
    "            if overlap >= overlap_ratio and (not same_label or a['label'] == b['label']):\n",
    "                agreement_list.append((overlap, a, b))\n",
    "    return agreement_list\n",
    "\n",
    "def get_labels_no_agreement(labels, agreement, labeller):\n",
    "    # Get the labels of a list of annotations that are not in agreement\n",
    "    labels_not_in_agreement = []\n",
    "    for label in labels:\n",
    "        in_agreement = False\n",
    "        for agreement_tuple in agreement:\n",
    "            # agreement_tuple contains overlap ratio, annotation of labeller 1, annotation of labeller 2\n",
    "            if label == agreement_tuple[labeller]:\n",
    "                in_agreement = True\n",
    "                break\n",
    "        if not in_agreement:\n",
    "            labels_not_in_agreement.append(label)\n",
    "    return labels_not_in_agreement\n",
    "\n",
    "\n",
    "data['agreement_diff'] = data.apply(lambda row: get_agreement_list(row['labels_1'], row['labels_2']), axis=1)\n",
    "data['agreement_same'] = data.apply(lambda row: get_agreement_list(row['labels_1'], row['labels_2'], same_label=True), axis=1)\n",
    "data['labels_1_no_agreement_diff'] = data.apply(lambda row: get_labels_no_agreement(row['labels_1'], row['agreement_diff'], 1), axis=1)\n",
    "data['labels_2_no_agreement_diff'] = data.apply(lambda row: get_labels_no_agreement(row['labels_2'], row['agreement_diff'], 2), axis=1)\n",
    "data['labels_1_no_agreement_same'] = data.apply(lambda row: get_labels_no_agreement(row['labels_1'], row['agreement_same'], 1), axis=1)\n",
    "data['labels_2_no_agreement_same'] = data.apply(lambda row: get_labels_no_agreement(row['labels_2'], row['agreement_same'], 2), axis=1)\n",
    "\n",
    "# Check for labeller 1 and labeller 2 that number of labels in agreement and not in agreement are the same as the total number of labels\n",
    "assert data.apply(lambda row: len(row['labels_1']) == len(row['agreement_diff']) + len(row['labels_1_no_agreement_diff']), axis=1).all()\n",
    "assert data.apply(lambda row: len(row['labels_2']) == len(row['agreement_diff']) + len(row['labels_2_no_agreement_diff']), axis=1).all()\n",
    "assert data.apply(lambda row: len(row['labels_1']) == len(row['agreement_same']) + len(row['labels_1_no_agreement_same']), axis=1).all()\n",
    "assert data.apply(lambda row: len(row['labels_2']) == len(row['agreement_same']) + len(row['labels_2_no_agreement_same']), axis=1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included 12 documents ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12])\n",
      "Total labels rater 1: 24\n",
      "Total labels rater 2: 8\n",
      "Total labels in 0.8 agreement w/ diff labels: 3 (12.50%, 37.50%)\n",
      "Total labels in 0.8 agreement w/ same labels: 2 (8.33%, 25.00%)\n"
     ]
    }
   ],
   "source": [
    "# Print general statistics\n",
    "total_labels_1 = data['labels_1'].apply(len).sum()\n",
    "total_labels_2 = data['labels_2'].apply(len).sum()\n",
    "total_agreement_diff = data['agreement_diff'].apply(len).sum()\n",
    "total_agreement_same = data['agreement_same'].apply(len).sum()\n",
    "\n",
    "print(f\"Included {len(included_ids)} documents ({included_ids})\")\n",
    "print(f\"Total labels rater 1: {total_labels_1}\")\n",
    "print(f\"Total labels rater 2: {total_labels_2}\")\n",
    "print(f\"Total labels in {overlap_ratio} agreement w/ diff labels: {total_agreement_diff} ({total_agreement_diff / total_labels_1 * 100:.2f}%, {total_agreement_diff / total_labels_2 * 100:.2f}%)\")\n",
    "print(f\"Total labels in {overlap_ratio} agreement w/ same labels: {total_agreement_same} ({total_agreement_same / total_labels_1 * 100:.2f}%, {total_agreement_same / total_labels_2 * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statistics per document with the following format:\n",
    "# document id\n",
    "#   Rater 1: total labels rater 1 (total labels in agreement w/ diff labels, total labels in agreement w/ same labels)\n",
    "#   Rater 2: total labels rater 2 (total labels in agreement w/ diff labels, total labels in agreement w/ same labels)\n",
    "#   Both Raters: list of labels annotated by both raters with different labels\n",
    "#   Only Rater 1: list of labels only annotated by rater 1 with different labels\n",
    "#   Only Rater 2: list of labels only annotated by rater 2 with different labels\n",
    "\n",
    "def format_label(label):\n",
    "    # Label is a dict with keys start, end, length, label, text\n",
    "    return f\"{label['text']} {label['start']}-{label['end']} ({label['label']})\"\n",
    "\n",
    "def format_labels(labels):\n",
    "    # Format as numbered list\n",
    "    return '\\n'.join([f\"\\t{i+1}. {format_label(l)}\" for i, l in enumerate(labels)])\n",
    "\n",
    "def format_agreement(agreement):\n",
    "    # agreement is a tuple with overlap ratio, annotation of labeller 1, annotation of labeller 2\n",
    "    text = f\"{agreement[0]:.2f} {agreement[1]['text']} vs. {agreement[2]['text']} {agreement[1]['start']}-{agreement[1]['end']}/{agreement[2]['start']}-{agreement[2]['end']}\"\n",
    "    if agreement[1]['label'] != agreement[2]['label']:\n",
    "        text += f\" ({agreement[1]['label']} vs. {agreement[2]['label']})\"\n",
    "    return text\n",
    "\n",
    "def format_agreements(agreements):\n",
    "    # Format as numbered list\n",
    "    return ('\\n' if len(agreements) > 0 else '') + '\\n'.join([f\"\\t{i+1}. {format_agreement(a)}\" for i, a in enumerate(agreements)])\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    print(f\"Document {row['id']}\")\n",
    "    print(f\"  Rater 1: {len(row['labels_1'])}\")\n",
    "    print(f\"  Rater 2: {len(row['labels_2'])}\")\n",
    "    print(f\"  Both Raters ({len(row['agreement_diff'])}):{format_agreements(row['agreement_diff'])}\")\n",
    "    print(f\"  Only Rater 1 ({len(row['labels_1_no_agreement_diff'])}):{format_labels(row['labels_1_no_agreement_diff'])}\")\n",
    "    print(f\"  Only Rater 2 ({len(row['labels_2_no_agreement_diff'])}):{format_labels(row['labels_2_no_agreement_diff'])}\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 resection of an inguinal mass procedure_unsupported condition_unsupported\n"
     ]
    }
   ],
   "source": [
    "# Print labels for each document that have an overlap of 80% or more\n",
    "for document_id in labeling_1_dict:\n",
    "    if document_id in labeling_2_dict:\n",
    "        # Get annotations for document\n",
    "        annotations_1 = labeling_1_dict[document_id]\n",
    "        annotations_2 = labeling_2_dict[document_id]\n",
    "        # Get all annotations that overlap 80% or more\n",
    "        overlapping_annotations = []\n",
    "        for a1 in annotations_1:\n",
    "            for a2 in annotations_2:\n",
    "                if a1['start'] >= a2['start'] and a1['start'] <= a2['end']:\n",
    "                    overlapping_annotations.append((a1, a2))\n",
    "                    break\n",
    "                elif a2['start'] >= a1['start'] and a2['start'] <= a1['end']:\n",
    "                    overlapping_annotations.append((a1, a2))\n",
    "                    break\n",
    "        # Print annotations\n",
    "        for a1, a2 in overlapping_annotations:\n",
    "            print(document_id, a1['text'], a1['label'], a2['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avs_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
