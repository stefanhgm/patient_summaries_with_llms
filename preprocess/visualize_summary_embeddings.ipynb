{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings of Summaries with Different Filter Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from datasets import load_dataset\n",
    "import plotly.express as px\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch\n",
    "import pickle\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7024add4c0d43769b3c295e64acce49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ac24b834f14d018d207b595a476eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9db85889a484a1780c9ebdfba1ca45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99e6fb06ec04a8cb5232c9e56356664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f392e13b7c44e01bc3348eb58e9f4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47657800ab244ac89f883106b919e660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 MIMIC-IV\n",
      "Loaded 10000 MIMIC-IV (preprocessed)\n"
     ]
    }
   ],
   "source": [
    "# Incorporate test predictions so use test sets\n",
    "mimic4_unfiltered_path = '/home/s_hegs02/mimic-iv-note-di/dataset/embeddings/embeddings_all_unprocessed_services_test.json'\n",
    "mimic4_filtered_path = '/home/s_hegs02/mimic-iv-note-di/dataset/embeddings/embeddings_all_services_test.json'\n",
    "\n",
    "mimic4_unfiltered = load_dataset('json', data_files=mimic4_unfiltered_path)['train']\n",
    "mimic4_filtered = load_dataset('json', data_files=mimic4_filtered_path)['train']\n",
    "\n",
    "print(f\"Loaded {len(mimic4_unfiltered)} MIMIC-IV\")\n",
    "print(f\"Loaded {len(mimic4_filtered)} MIMIC-IV (preprocessed)\")\n",
    "\n",
    "# Only select 10k examples\n",
    "mimic4_unfiltered = mimic4_unfiltered.select(range(10000))\n",
    "mimic4_filtered = mimic4_filtered.select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1c8d6201e040ddbc41679e16824ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628107b795f34033a9eee45b89de3dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9713242b24184602abc059d8d1b82cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa72de32d5b4969b3bb01c5e5fe91e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a079e3db9ac4451a592e4c29f1adc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load HF models\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIMIC-IV: 0.1119\n",
      "MIMIC-IV (preprocessed): 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Get token distributions\n",
    "def get_token_distributions(dataset):\n",
    "    num_tokens = [len(tokenizer.tokenize(ex)) for ex in dataset['summary']]\n",
    "    return num_tokens\n",
    "    \n",
    "# Print ratio of summaries longer than 512 tokens - cannot use the full summary for those\n",
    "print(f\"MIMIC-IV: {sum([1 for n in get_token_distributions(mimic4_unfiltered) if n > 512]) / len(mimic4_unfiltered)}\")\n",
    "print(f\"MIMIC-IV (preprocessed): {sum([1 for n in get_token_distributions(mimic4_filtered) if n > 512]) / len(mimic4_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cls embedding tokens for all summaries\n",
    "def get_cls_embedding(batch):\n",
    "    inputs = tokenizer(batch['summary'], padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "    last_hidden_states = outputs.hidden_states[-1]\n",
    "    cls_embedding = last_hidden_states[:,0,:]\n",
    "    return {'cls_embedding': cls_embedding}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e1361bfb28449391776b1a9eeacdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3656338f71da4dfa8b707f53021c6f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mimic4_unfiltered = mimic4_unfiltered.map(get_cls_embedding, batched=True, batch_size=32)  # Adapt batch_size to your GPU memory\n",
    "mimic4_filtered = mimic4_filtered.map(get_cls_embedding, batched=True, batch_size=32)  # Adapt batch_size to your GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tsne embeddings to dataset\n",
    "def create_tsne_embeddings(dataset):\n",
    "    cls_embeddings = np.array([ex for ex in dataset['cls_embedding']])\n",
    "    embeddings = TSNE(n_components=2, random_state=1).fit_transform(cls_embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic4_unfiltered_tsne = create_tsne_embeddings(mimic4_unfiltered)\n",
    "mimic4_filtered_tsne = create_tsne_embeddings(mimic4_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize tsne embeddings\n",
    "def normalize_tsne_embeddings(embeddings):\n",
    "    return (embeddings - embeddings.min()) / (embeddings.max() - embeddings.min())\n",
    "\n",
    "mimic4_unfiltered_tsne = normalize_tsne_embeddings(mimic4_unfiltered_tsne)\n",
    "mimic4_filtered_tsne = normalize_tsne_embeddings(mimic4_filtered_tsne)\n",
    "\n",
    "# Convert to lists to change ordering easily\n",
    "mimic4_unfiltered_tsne = mimic4_unfiltered_tsne.tolist()\n",
    "mimic4_filtered_tsne = mimic4_filtered_tsne.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sumamries from datasets\n",
    "def extract_summaries(dataset):\n",
    "    return [ex for ex in dataset['summary']]\n",
    "\n",
    "mimic4_unfiltered_summaries = extract_summaries(mimic4_unfiltered)\n",
    "mimic4_filtered_summaries = extract_summaries(mimic4_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add label classes for scatter plot to color dots\n",
    "# Different options:\n",
    "# 1. No labels (dummies)\n",
    "# 2. Medical services (given in MIMIC notes)\n",
    "# 3. Prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. No labels (dummies)\n",
    "mimic4_unfiltered_classes = [1 for x in mimic4_unfiltered]\n",
    "mimic4_filtered_classes = [1 for x in mimic4_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Medical services (given in MIMIC notes)\n",
    "# We assume the medical services where (wrongly) stored in the text field of the summary\n",
    "# Counts: ('MEDICINE', 195679), ('SURGERY', 46529), ('ORTHOPAEDICS', 18302), ('NEUROLOGY', 18056), ('CARDIOTHORACIC', 13786), ('NEUROSURGERY', 10638), ('OBSTETRICS/GYNECOLOGY', 9522), ('PSYCHIATRY', 7560), ('UROLOGY', 4947), ('PLASTIC', 3363), ('PODIATRY', 1315), ('OTOLARYNGOLOGY', 851), ('UNKNOWN', 653), ('OME', 362), ('EMERGENCY', 136), ('ANESTHESIOLOGY', 43), ('BIOLOGIC', 24), ('DENTAL', 14), ('RADIATION', 5), ('OPHTHALMOLOGY', 4), ('RADIOLOGY', 4)]\n",
    "# Map medical services to 10 most common classes\n",
    "map_services = {'MEDICINE': 'medicine', 'SURGERY': 'surgery', 'ORTHOPAEDICS': 'orthopaedics', 'NEUROLOGY': 'neurology', 'CARDIOTHORACIC': 'cardiothoracic', 'NEUROSURGERY': 'neurosurgery', 'OBSTETRICS/GYNECOLOGY': 'obs/gyn', 'PSYCHIATRY': 'psychiatry', 'UROLOGY': 'urology', 'PLASTIC': 'other', 'PODIATRY': 'other', 'OTOLARYNGOLOGY': 'other', 'UNKNOWN': 'other', 'OME': 'other', 'EMERGENCY': 'other', 'ANESTHESIOLOGY': 'other', 'BIOLOGIC': 'other', 'DENTAL': 'other', 'RADIATION': 'other', 'OPHTHALMOLOGY': 'other', 'RADIOLOGY': 'other'}\n",
    "services = ['medicine', 'surgery', 'orthopaedics', 'neurology', 'cardiothoracic', 'neurosurgery', 'obs/gyn', 'psychiatry', 'urology', 'other']\n",
    "\n",
    "mimic4_unfiltered_classes = [map_services[ex['text']] for ex in mimic4_unfiltered]\n",
    "mimic4_filtered_classes = [map_services[ex['text']] for ex in mimic4_filtered]\n",
    "\n",
    "# Move one value for each class in services at first positions of mimic4_unfiltered_classes and mimic4_filtered_classes\n",
    "# This is done to ensure that the legend of the plot shows the correct colors for each class\n",
    "for service in reversed(services):\n",
    "    for i, c in enumerate(mimic4_unfiltered_classes):\n",
    "        if c == service:\n",
    "            mimic4_unfiltered_classes.insert(0, mimic4_unfiltered_classes.pop(i))\n",
    "            mimic4_unfiltered_summaries.insert(0, mimic4_unfiltered_summaries.pop(i))\n",
    "            mimic4_unfiltered_tsne.insert(0, mimic4_unfiltered_tsne.pop(i))\n",
    "            break\n",
    "    for i, c in enumerate(mimic4_filtered_classes):\n",
    "        if c == service:\n",
    "            mimic4_filtered_classes.insert(0, mimic4_filtered_classes.pop(i))\n",
    "            mimic4_filtered_summaries.insert(0, mimic4_filtered_summaries.pop(i))\n",
    "            mimic4_filtered_tsne.insert(0, mimic4_filtered_tsne.pop(i))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prediction results\n",
    "\n",
    "# Prediction metrics for LED-large model\n",
    "# * Trained on 100000 steps\n",
    "# * max_source_length 16384 and max_target_length 512 \n",
    "\n",
    "# Use custom rouge function to obtain rouge 3/4 which are not available in huggingface\n",
    "def get_rouge_score(gold, pred):\n",
    "    rouge_scores = ['rouge1', 'rouge2', 'rouge3', 'rouge4', 'rougeL']\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_scores, use_stemmer=True)\n",
    "    scores = scorer.score(gold, pred)\n",
    "    return {k: scores[k].fmeasure * 100 for k in rouge_scores}\n",
    "\n",
    "# Metrics obtained with eval_summarization.py on test predictions\n",
    "# TODO This is the filtered one\n",
    "mimic4_unfiltered_pred_path = '/home/s_hegs02/mimic-iv-note-di/models/led-large-16384/mimic-iv-note-di-embeddings/processed-200k-steps/test_generations.pkl'\n",
    "mimic4_filtered_pred_path = '/home/s_hegs02/mimic-iv-note-di/models/led-large-16384/mimic-iv-note-di-embeddings/unprocessed-200k-steps/test_generations.pkl'\n",
    "mimic4_unfiltered_pred = pickle.load(open(mimic4_unfiltered_pred_path, 'rb'))\n",
    "mimic4_filtered_pred = pickle.load(open(mimic4_filtered_pred_path, 'rb'))\n",
    "\n",
    "mimic4_unfiltered_metrics = [get_rouge_score(gold, pred) for gold, pred in zip(mimic4_unfiltered_summaries, mimic4_unfiltered_pred)]\n",
    "mimic4_filtered_metrics = [get_rouge_score(gold, pred) for gold, pred in zip(mimic4_filtered_summaries, mimic4_filtered_pred)]\n",
    "\n",
    "# mimic4_unfiltered_metrics_path = '/home/s/s_hegs02/scratch/mimic-iv-avs_reproduced/models/output-train-led-base/test_generations_metrics.pkl'\n",
    "# mimic4_filtered_metrics_path = '/home/s/s_hegs02/scratch/mimic-iv-avs/models/output-train-led-base/test_generations_metrics.pkl'\n",
    "# mimic4_unfiltered_metrics = pd.read_pickle(mimic4_unfiltered_metrics_path)\n",
    "# mimic4_filtered_metrics = pd.read_pickle(mimic4_filtered_metrics_path)\n",
    "# \n",
    "metric = 'rouge1'\n",
    "mimic4_unfiltered_classes = [int(m[metric]) for m in mimic4_unfiltered_metrics]\n",
    "mimic4_filtered_classes = [int(m[metric]) for m in mimic4_filtered_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({28: 458, 29: 448, 30: 430, 26: 429, 27: 427, 25: 425, 24: 408, 22: 380, 32: 380, 23: 378, 20: 348, 31: 339, 18: 338, 21: 338, 19: 328, 16: 299, 17: 297, 33: 297, 15: 287, 14: 281, 34: 270, 0: 249, 13: 243, 35: 228, 12: 224, 11: 190, 36: 168, 10: 149, 37: 137, 9: 119, 38: 104, 2: 82, 8: 70, 40: 66, 39: 58, 7: 55, 6: 44, 5: 41, 41: 38, 4: 38, 42: 28, 3: 23, 43: 18, 1: 14, 44: 12, 45: 8, 48: 3, 47: 3, 46: 2, 50: 1})\n",
      "Counter({27: 474, 25: 466, 29: 455, 26: 453, 28: 423, 20: 422, 22: 414, 23: 413, 30: 408, 31: 404, 24: 389, 21: 378, 18: 375, 32: 372, 19: 366, 33: 336, 17: 334, 34: 325, 16: 315, 0: 278, 15: 254, 35: 230, 14: 216, 36: 194, 37: 179, 13: 170, 12: 147, 38: 117, 39: 81, 11: 77, 10: 72, 40: 69, 2: 57, 9: 56, 1: 41, 41: 37, 42: 36, 8: 31, 43: 24, 7: 20, 4: 16, 44: 15, 5: 15, 3: 14, 6: 14, 45: 8, 46: 4, 47: 3, 49: 1, 50: 1, 48: 1})\n"
     ]
    }
   ],
   "source": [
    "# Print counts of all avlues in mimic4_unfiltered_classes and mimic4_filtered_classes\n",
    "print(Counter(mimic4_unfiltered_classes))\n",
    "print(Counter(mimic4_filtered_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "def create_labeled_hover_sp(summaries, embeddings, classes):\n",
    "    hover_labels = [re.sub(\"(.{64})\", \"\\\\1<br>\", ex, 0, re.DOTALL) for ex in summaries]\n",
    "    \n",
    "    # 2. Medical services: Discrete color scale\n",
    "    # fig = px.scatter(x=np.array(embeddings)[:,0], y=np.array(embeddings)[:,1], hover_name=hover_labels, color=classes, width=900, height=600)\n",
    "    # fig.update_layout(legend_title_text='Medical services')\n",
    "    \n",
    "    # 3. Prediction results: Continuous color scale\n",
    "    fig = px.scatter(x=np.array(embeddings)[:,0], y=np.array(embeddings)[:,1], hover_name=hover_labels, color=classes, width=900, height=600, color_continuous_scale='viridis')\n",
    "    # Name continuous color scale\n",
    "    fig.update_layout(coloraxis_colorbar=dict(title='ROUGE-1'))\n",
    "    fig.update_layout(coloraxis=dict(cmin=0, cmax=50))\n",
    "    \n",
    "    # Set all margins to zero\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "    \n",
    "    # Change legend and axis font size to 20\n",
    "    fig.update_layout(legend=dict(font=dict(size=20)), font=dict(size=20))\n",
    "    \n",
    "    # Axis ticks at 0, 0.2, 0.4, 0.6, 0.8, 1\n",
    "    fig.update_xaxes(tickvals=[0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    fig.update_yaxes(tickvals=[0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    return fig\n",
    "\n",
    "# create_labeled_hover_sp(mimic4_unfiltered_summaries, mimic4_unfiltered_tsne, mimic4_unfiltered_classes).show() \n",
    "# create_labeled_hover_sp(mimic4_filtered_summaries, mimic4_filtered_tsne, mimic4_filtered_classes).show()\n",
    "\n",
    "# Store as pdf\n",
    "# create_labeled_hover_sp(mimic4_unfiltered_summaries, mimic4_unfiltered_tsne, mimic4_unfiltered_classes).write_image(\"/home/s_hegs02/patient_summaries_with_llms/mimic4_emb_unfiltered_services.pdf\")\n",
    "# create_labeled_hover_sp(mimic4_filtered_summaries, mimic4_filtered_tsne, mimic4_filtered_classes).write_image(\"/home/s_hegs02/patient_summaries_with_llms/mimic4_emb_filtered_services.pdf\")\n",
    "\n",
    "# create_labeled_hover_sp(mimic4_unfiltered_summaries, mimic4_unfiltered_tsne, mimic4_unfiltered_classes).write_image(\"/home/s_hegs02/patient_summaries_with_llms/mimic4_emb_unfiltered_embeddings.pdf\")\n",
    "# create_labeled_hover_sp(mimic4_filtered_summaries, mimic4_filtered_tsne, mimic4_filtered_classes).write_image(\"/home/s_hegs02/patient_summaries_with_llms/mimic4_emb_filtered_embeddings.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avs_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
